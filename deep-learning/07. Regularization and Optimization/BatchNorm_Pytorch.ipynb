{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rim8RvFq0GqH"
      },
      "source": [
        "## BatchNorm Implementation in PyTorch\n",
        "\n",
        "BatchNorm is one of the techniques used in deep learning to improve generalization.\n",
        "\n",
        "Though the concept of BatchNorm is the same for both training and inference, there are some slight differences:\n",
        "\n",
        "### Training\n",
        "\n",
        "**Step 1) Normalize net inputs**\n",
        "\n",
        "- Compute mean and variance over the entire batch:\n",
        "  \n",
        "  mean = (1 / N) * Σ (X_i), where N is the batch size.\n",
        "\n",
        "  var = (1 / N) * Σ (X_i - mean)², where X_i is each individual element in the batch.\n",
        "\n",
        "- Standardize the net input:\n",
        "  \n",
        "  X̂_i = (X_i - mean) / sqrt(var + ε), where ε is a small constant added for numerical stability.\n",
        "\n",
        "- A **running mean** and **running variance** are computed because we don't calculate the mean/variance over the batch during inference and simply use the running mean and variance.\n",
        "\n",
        "**Step 2) Scaling**\n",
        "\n",
        "- We use learnable parameters α (gamma) and β (beta), which are updated via backpropagation:\n",
        "  \n",
        "  Y_i = γ * X̂_i + β, where γ and β are trainable parameters.\n",
        "\n",
        "### Inference\n",
        "\n",
        "**Step 1) Normalize net inputs**\n",
        "\n",
        "- During inference, the mean and variance are replaced by the **running mean** and **running variance** that were computed during training:\n",
        "  \n",
        "  X̂_i = (X_i - running_mean) / sqrt(running_variance + ε)\n",
        "\n",
        "**Step 2) Scaling**\n",
        "\n",
        "- The scaling and shifting still happen using the learned parameters α and β:\n",
        "  \n",
        "  Y_i = γ * X̂_i + β\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "3ELqiceP0OVE"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xOXIZi61yfN"
      },
      "outputs": [],
      "source": [
        "class BatchNorm1D(torch.nn.Module):\n",
        "  def __init__(self,num_features,momentum=0.1):\n",
        "    super().__init__()\n",
        "    self.num_features=num_features\n",
        "    self.gamma=torch.nn.Parameter(torch.ones(num_features))\n",
        "    self.beta=torch.nn.Parameter(torch.zeros(num_features))\n",
        "    self.running_mean=torch.zeros(1,num_features)\n",
        "    self.running_var=torch.ones(1,num_features)\n",
        "    self.momentum=momentum\n",
        "\n",
        "  def __call__(self,X):\n",
        "    mean=torch.mean(X,dim=0,keepdim=True) if self.training else self.running_mean\n",
        "    var=torch.var(X,dim=0,keepdim=True) if self.training else self.running_var\n",
        "    if self.training:\n",
        "      self.running_mean=mean*self.momentum + self.running_mean*(1-self.momentum)\n",
        "      self.running_var=var*self.momentum + self.running_var*(1-self.momentum)\n",
        "    epsilon=1e-10\n",
        "    denominator=(var + epsilon)**(1/2)\n",
        "    z=(X-mean)/denominator\n",
        "    return self.gamma*z+self.beta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "z047pFkR3-XS"
      },
      "outputs": [],
      "source": [
        "batchnorm=BatchNorm1D(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjB6iE5s4MeS",
        "outputId": "4ebff22e-3adc-4d4e-c389-2c5dfe4802fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before Training: Running Mean tensor([[0., 0., 0., 0., 0.]])\n",
            "Before Training: Running Variance tensor([[1., 1., 1., 1., 1.]])\n",
            "\n",
            "After Training: Running Mean tensor([[-0.0108, -0.0365, -0.0032,  0.0061,  0.0076]])\n",
            "After Training: Running Variance tensor([[1.0004, 0.9924, 0.9642, 1.0476, 0.9745]])\n",
            "\n",
            "After More Training: Running Mean tensor([[ 0.0036, -0.0325,  0.0338, -0.0244,  0.0169]])\n",
            "After More Training: Running Variance tensor([[0.9529, 0.9682, 0.9505, 0.9808, 0.9394]])\n"
          ]
        }
      ],
      "source": [
        "batchnorm.train()\n",
        "print(f\"Before Training: Running Mean {batchnorm.running_mean}\")\n",
        "print(f\"Before Training: Running Variance {batchnorm.running_var}\\n\")\n",
        "\n",
        "batchnorm(torch.randn(10,5))\n",
        "\n",
        "\n",
        "print(f\"After Training: Running Mean {batchnorm.running_mean}\")\n",
        "print(f\"After Training: Running Variance {batchnorm.running_var}\\n\")\n",
        "\n",
        "batchnorm(torch.randn(10,5))\n",
        "\n",
        "\n",
        "print(f\"After More Training: Running Mean {batchnorm.running_mean}\")\n",
        "print(f\"After More Training: Running Variance {batchnorm.running_var}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YJG_mlI4Uxx",
        "outputId": "2460680c-a87e-4640-f2c5-138e6797a26a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before Inference: Running Mean tensor([[ 0.0036, -0.0325,  0.0338, -0.0244,  0.0169]])\n",
            "Before Inference: Running Variance tensor([[0.9529, 0.9682, 0.9505, 0.9808, 0.9394]])\n",
            "\n",
            "After Inference: Running Mean tensor([[ 0.0036, -0.0325,  0.0338, -0.0244,  0.0169]])\n",
            "After Inference: Running Variance tensor([[0.9529, 0.9682, 0.9505, 0.9808, 0.9394]])\n"
          ]
        }
      ],
      "source": [
        "batchnorm.eval()\n",
        "print(f\"Before Inference: Running Mean {batchnorm.running_mean}\")\n",
        "print(f\"Before Inference: Running Variance {batchnorm.running_var}\\n\")\n",
        "\n",
        "batchnorm(torch.randn(10,5))\n",
        "\n",
        "\n",
        "print(f\"After Inference: Running Mean {batchnorm.running_mean}\")\n",
        "print(f\"After Inference: Running Variance {batchnorm.running_var}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "XfUaXyzT8fWu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
